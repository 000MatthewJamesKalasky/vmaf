##Contributing to VMAF

If you would like to contribute code you can do so through GitHub by forking the repository and sending a pull request. When submitting code, please make every effort to follow existing conventions and style in order to keep the code as readable as possible.

###License

By contributing your code, you agree to license your contribution under the terms of the [Apache License v2.0](http://www.apache.org/licenses/LICENSE-2.0). Your contributions should also include the following header:

```
/**
 * Copyright 2016 the original author or authors.
 * 
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 * 
 * http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
```

##Repository Structure

Files in the repository follows the structure below:

```
├── feature: C/C++ source code for extraction of features
├── libsvm: libsvm C/C++ source code
├── python
│   ├── config.py: configuration info such as paths, global parameters, etc. 
│   ├── core: core classes and functions
│   ├── script: scripts for executing specific tasks
│   ├── test: unit/functional test cases
│   └── tools: common reusable classes and functions
├── resource
│   ├── dataset: dataset files
│   ├── feature_param: feature parameter files
│   ├── images
│   ├── model: permanent trained model files
│   ├── model_param: model parameter files
│   └── yuv: sample YUV video files
└── workspace
    ├── log_file_dir: intermediate Executor log files
    ├── model: output trained model files
    ├── model_param: output model parameter files generated by hyper-parameter search
    ├── result_store_dir: result store files
    └── workdir: working directory
```
 
##Core Classes

The relationship among the core classes can be represented in the diagram below:

![UML](/resource/images/uml.png)

####Asset

An Asset provide info about a distored video and its reference video, as well as information on how its quality should be measured (e.g. start/end frames, upscale to what resolution to its quality). It is used as an input to an executor (e.g. a QualityRunner, or a FeatureExtractor). Asset is has a unique working directory to enable thread safety.

####Executor

An Executor takes in a list of Assets, and run calculation on them, and return a list of corresponding results. An Executor must specify a unique type and version combination (by the TYPE and VERSION attribute), so that the Result generated by it can be identified.

####Result

Dictionary-like key-value store of read-only result generated on an Asset by a Executor.

####ResultStore

Provide capability to save and load a Result.

####FeatureExtractor

FeatureExtractor takes in a list of assets, and run feature extraction on them, and return a list of corresponding results. A FeatureExtractor must specify a unique type and version combination (by the TYPE and VERSION attribute), so that the Result generated by it can be identified.

####FeatureAssembler

Assembles features for a input list of Assets on a input list of FeatureExtractors. For each asset, it outputs a BasicResult object.

####TrainTestModel

To add.

####QualityRunner

QualityRunner takes in a list of assets, and run quality assessment on them, and return a list of corresponding results. A QualityRunner must specify a unique type and version combination (by the TYPE and VERSION attribute), so that the Result generated by it can be identified.

##Extending Classes

###Extending QualityRunner

There are two ways to create a derived class of QualityRunner:

  a) Call a command-line exectuable directly, very similar to what FeatureExtractor does. You must:
    
    1) Override TYPE and VERSION
    
    2) Override _run_and_generate_log_file(self, asset), which call a command-line executable and generate quality scores in a log file.
    
    3) Override _get_quality_scores(self, asset), which read the quality scores from the log file, and return the scores in a dictionary format.
    
    4) If necessary, override _remove_log(self, asset) if Executor._remove_log(self, asset) doesn't work for your purpose (sometimes the command-line executable could generate output log files in some different format, like multiple files).
    
  For an example, follow PsnrQualityRunner.

  b) Override the Executor._run_on_asset(self, asset) method to bypass the regular routine, but instead, in the method construct a FeatureAssembler (which calls a FeatureExtractor (or many) and assembles a list of features, followed by using a TrainTestModel (pre-trained somewhere else) to predict the final quality score. You must:
    
    1) Override TYPE and VERSION
    
    2) Override _run_on_asset(self, asset), which runs a FeatureAssembler, collect a feature vector, run TrainTestModel.predict() on it, and return a Result object (in this case, both Executor._run_on_asset(self, asset) and QualityRunner._read_result(self, asset) get bypassed.
    
    3) Override _remove_log(self, asset) by redirecting it to the FeatureAssembler.
    
    4) Override _remove_result(self, asset) by redirecting it to the FeatureAssembler.
  
  For an example, follow VmafQualityRunner.

###Extending FeatureExtractor

###Extending TrainTestModel

